# üöï Projet Big Data Streaming : Calculateur de Co√ªt de Trajet Taxi

Ce projet impl√©mente le backend d'un pipeline de donn√©es en temps r√©el pour une application de taxi. Il calcule le co√ªt d'un trajet en fonction de la distance et du confort, traite les donn√©es via **Kafka** et **Airflow**, puis les stocke dans **Elasticsearch**, **GCS** et **BigQuery** pour visualisation et analyse.

[![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)](https://www.python.org/) [![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://www.docker.com/) [![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat&logo=apacheairflow&logoColor=white)](https://airflow.apache.org/) [![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=flat&logo=apachekafka&logoColor=white)](https://kafka.apache.org/) [![Elasticsearch](https://img.shields.io/badge/Elasticsearch-005571?style=flat&logo=elasticsearch&logoColor=white)](https://www.elastic.co/elasticsearch/) [![Kibana](https://img.shields.io/badge/Kibana-005571?style=flat&logo=kibana&logoColor=white)](https://www.elastic.co/kibana/) [![Google Cloud](https://img.shields.io/badge/Google%20Cloud-4285F4?style=flat&logo=googlecloud&logoColor=white)](https://cloud.google.com/)

---

## üèõÔ∏è Architecture

Le pipeline de donn√©es utilise les technologies suivantes, orchestr√©es localement avec `docker-compose` :

* **Kafka :** Bus de messages pour l'ingestion et la communication entre les √©tapes.
* **Airflow :** Orchestrateur des workflows (DAGs) de traitement.
* **Elasticsearch :** Base de donn√©es NoSQL pour l'indexation et la recherche.
* **Kibana :** Outil de visualisation et de dashboarding pour les donn√©es Elasticsearch.
* **Google Cloud Storage (GCS) :** Stockage objet pour les donn√©es brutes (Data Lake).
* **Google BigQuery :** Data Warehouse pour l'analyse et le stockage structur√©.

---

## üåä Flux de Donn√©es (DAGs Airflow)

Deux DAGs Airflow g√®rent le traitement :

1.  **`dag1_travel_cost` :**
    * Consomme les donn√©es brutes depuis un topic Kafka (`source`).
    * Calcule la distance (via `geopy`) et le co√ªt du trajet (`ComputCostTravel`).
    * Publie le r√©sultat enrichi dans un autre topic Kafka (`result`).
2.  **`dag2_data_sink` :**
    * Consomme les donn√©es enrichies depuis le topic Kafka (`result`).
    * Transforme le message JSON en un format plat (`TransFormJson`).
    * Indexe le r√©sultat dans Elasticsearch (`PutElasticSearch`).
    * Stocke les donn√©es brutes (JSON) dans **GCS** et les donn√©es transform√©es (lignes) dans **BigQuery** (`PutGCP`).

---

## üöÄ D√©marrage Rapide (MVP Local)

1.  **Pr√©requis :** Assurez-vous que Docker Desktop est install√© et en cours d'ex√©cution.

2.  **Configuration GCP :**
    * Cr√©ez un compte de service GCP avec les r√¥les `BigQuery Data Editor` et `Storage Object Creator`.
    * T√©l√©chargez sa cl√© JSON.
    * Cr√©ez le bucket GCS `my-taxi-bucket-eu`.
    * Cr√©ez le dataset BigQuery `travel_logs` (location `EU`) et la table `rides` avec le sch√©ma appropri√©.

3.  **Configuration Airflow :**
    * Lancez les services une premi√®re fois : `docker compose up -d`.
    * Acc√©dez √† Airflow (`http://localhost:8080`). Trouvez le mot de passe `admin` avec `docker compose logs airflow-standalone | grep "password"`.
    * Allez dans **Admin > Connections > +** et cr√©ez une connexion :
        * **Conn Id :** `google_cloud_default`
        * **Conn Type :** `Google Cloud`
        * **Keyfile JSON :** Collez le contenu complet de votre cl√© JSON GCP.
        * Sauvegardez.
    * Arr√™tez les services : `docker compose down`.

4.  **Lancement Complet :**
    * Placez votre fichier de donn√©es initiales dans `./data/data_projet.json`.
    * Lancez tous les services : `docker compose up -d --build`.

5.  **Acc√®s aux Outils :**
    * **Airflow :** `http://localhost:8080`
    * **Kibana :** `http://localhost:5601`

6.  **Ex√©cution du Pipeline :**
    * Dans Airflow, activez et d√©clenchez `dag1_travel_cost`, attendez le succ√®s ‚úÖ.
    * Activez et d√©clenchez `dag2_data_sink`, attendez le succ√®s ‚úÖ.

---

## üìä Visualisation (Kibana)

* Cr√©ez une **Data View** dans Kibana pour l'index `travel_data`.
* Explorez les donn√©es brutes dans l'onglet **Discover**.
* Cr√©ez des visualisations (ex: Graphiques "CA par Confort", Carte des localisations) et assemblez-les dans un **Dashboard**.

---

## üíæ Stockage (GCP)

* **Google Cloud Storage :** Les messages bruts (apr√®s calcul du co√ªt) sont stock√©s sous forme de fichiers JSON dans `gs://my-taxi-bucket-eu/rides_raw/`.
* **Google BigQuery :** Les donn√©es transform√©es et aplaties sont stock√©es dans la table `sorbonne-475119.travel_logs.rides`. Une table externe (`rides_external_json`) peut √©galement √™tre cr√©√©e pour lire directement depuis GCS.

---

## ü§ñ Analyse BQML (Clustering)

Une fois les donn√©es stock√©es dans BigQuery, elles peuvent √™tre exploit√©es directement via **BigQuery Machine Learning (BQML)** pour des analyses avanc√©es, sans n√©cessiter d'export de donn√©es.

* **Clustering KMeans :** Comme sugg√©r√© dans l'architecture de production, un mod√®le **KMeans** (par exemple, avec k=8) peut √™tre entra√Æn√© directement dans BQML.
* **Objectif :** Segmenter les trajets en clusters bas√©s sur des caract√©ristiques comme la localisation de d√©part/arriv√©e, le co√ªt, ou l'heure.
* **Analyse :** Ces clusters permettent ensuite d'analyser des m√©triques business, telles que le **revenu par cluster** ou le **revenu par cluster et par type de confort**, afin d'identifier des zones g√©ographiques ou des types de trajets √† forte valeur ajout√©e.

---

## üèóÔ∏è Proposition d'Architecture (Production)

Pour un environnement de production, l'architecture Kafka suivante est recommand√©e :

* **Brokers :** 3 (minimum pour la haute disponibilit√©).
* **Disques :** 1 To SSD par broker (pour la performance et la r√©tention).
* **Partitions :** 6 pour `source` (parall√©lisme pour DAG1), 3 pour `result` (parall√©lisme pour DAG2).
* **Monitoring :** Stack Prometheus (JMX Exporter) + Grafana pour les m√©triques, et Kowl (ou Redpanda Console) pour l'exploration des topics/messages.

### Sch√©ma de flux en production

```text
[Producer] -> Kafka (topic: source) -> Airflow DAG1 ----> Kafka (topic: result) -> Airflow DAG2
                                      (Calcul Co√ªt)                              (Flatten/Sink)
                                                                                      |
                                            +---------------------+-------------------+
                                            |                     |                   |
                                            v                     v                   v
                                      Elasticsearch            GCS (JSON)         BigQuery (Table)
                                            |                     |
                                            v                     v
                                         Kibana            BQ (External Table)
                                                                  |
                                                                  v
                                                           BQML (KMeans)
                                                                  |
                                                                  v
                                                    (Analyse Revenus / Cluster)
