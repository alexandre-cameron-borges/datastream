# Architecture Backend

## 1. Python/Simple pour l'intégration des données dans Kafka : 

- lancer 'start_kafka' pour lancer kafka
- créer un topic en ligne de commande
- pour voir les topic : 'cd C:\kafka\kafka_2.13-4.1.0' puis '.\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092'
- pour voir en tant réel tous les messages envoyés dans mon topic : '.\bin\windows\kafka-console-consumer.bat --topic uber_source --from-beginning --bootstrap-server localhost:9092'
- lancer producer_kafka.py

## 2. Airflow pour la transformation des données et l’ingestion dans Elasticsearch : 

- installation de Airflow avec Docker
- lancer Airflow : docker compose up
- se connecter : http://127.0.0.1:8080/


